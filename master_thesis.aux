\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Foltz1996}
\citation{DBLP:journals/corr/LeM14}
\citation{KaoudiQTCA17}
\citation{LiptonKEW15}
\citation{SakSB14}
\@writefile{toc}{\contentsline {part}{\numberline {I}Find similar Galaxy tools}{1}{part.1}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{2}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chap:introduction}{{1}{2}{Introduction}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Galaxy}{2}{section.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Basic flow of dataset transformation}}{2}{figure.caption.8}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Galaxy tools}{3}{section.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Common features of two tools using venn diagram}}{3}{figure.caption.9}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Motivation}{4}{section.1.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Similarity knowledge graph consisting of tools as nodes}}{4}{figure.caption.10}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Approach}{6}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chap:approach}{{2}{6}{Approach}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Extract tools data}{6}{section.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Select tools attributes}{6}{subsection.2.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Sequence of steps to find similar tools}}{7}{figure.caption.11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Clean tools data}{7}{subsection.2.1.2}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Remove duplicates and stopwords}{7}{section*.12}}
\citation{RobertsonBM25}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Use stemming}{8}{section*.13}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Learn relevance for words}{8}{section*.16}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Distribution of tokens for all the attributes of tools}}{9}{figure.caption.14}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Tool, document and tokens}}{10}{figure.caption.15}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces A sparse documents-tokens matrix}}{11}{table.caption.17}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:accuracy}{{1}{11}{A sparse documents-tokens matrix}{table.caption.17}{}}
\citation{Foltz1996}
\citation{Shapiro2000}
\citation{Landauer1998}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Heatmap for documents-tokens matrices}}{12}{figure.caption.18}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Learn dense vector for a document}{13}{section.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Latent semantic analysis}{13}{subsection.2.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Pictorial representation of singular value decomposition}}{13}{figure.caption.19}}
\citation{DBLP:journals/corr/Yang15b}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Low-rank approximation}{14}{section*.20}}
\citation{DBLP:journals/corr/LeM14}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Singular values of documents-tokens matrices}}{15}{figure.caption.21}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Singular values of documents-tokens matrices with their respective ranks}}{16}{figure.caption.22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Paragraph vectors}{16}{subsection.2.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces The variation of the fraction of ranks of documents-tokens matrices with the fraction of the sum of singular values}}{17}{figure.caption.23}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Approach}{17}{section*.25}}
\citation{DBLP:journals/corr/LeM14}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Low-rank representations of documents-tokens matrices}}{18}{figure.caption.24}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Distributed memory approach for paragraph vectors}}{19}{figure.caption.26}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Similarity measures}{19}{section.2.3}}
\newlabel{pv}{{9}{19}{}{Hfootnote.16}{}}
\citation{Ivchenko1998}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Distributed bag-of-words approach for paragraph vectors}}{20}{figure.caption.27}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Cosine similarity}{20}{subsection.2.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Jaccard index}{20}{subsection.2.3.2}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Optimization}{21}{section.2.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Gradient descent}{22}{subsection.2.4.1}}
\citation{articleRuderS}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Learning rate decay}{23}{subsection.2.4.2}}
\citation{articleRuderS}
\citation{Sutskever}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Decay of learning rate for gradient descent optimizer}}{24}{figure.caption.28}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Weight update}{24}{subsection.2.4.3}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Momentum}{24}{section*.29}}
\citation{Botev}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Nesterov\IeC {\textquoteright }s accelerated gradient}{25}{section*.30}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Gradient verification}{25}{section*.31}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Verification of gradient for the error function}}{26}{figure.caption.32}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Experiments}{27}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Amount of help text}{27}{section.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Number of attributes}{27}{section.3.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Similarity measures}{27}{section.3.3}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Latent semantic analysis}{27}{section.3.4}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Paragraph vectors}{28}{section.3.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Distributed bag-of-words}{28}{subsection.3.5.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Gradient descent}{28}{section.3.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.1}Learning rates}{29}{subsection.3.6.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Code repositories}{29}{section.3.7}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Results and analysis}{30}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Latent semantic analysis}{30}{section.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Full-rank matrices}{30}{subsection.4.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}70\% of full-rank}{30}{subsection.4.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}30\% of full-rank}{31}{subsection.4.1.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.4}5\% of full-rank}{31}{subsection.4.1.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.5}Improvement verification}{31}{subsection.4.1.5}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Reduction in error}{31}{section*.41}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Static visualizer}{32}{section*.45}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Paragraph vectors}{32}{section.4.2}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Static visualizer}{33}{section*.46}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Comparison of latent semantic analysis and paragraph vectors approaches}{33}{section.4.3}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Similar tools (top-2) for "hisat" extracted using full-rank documents-tokens matrices}}{34}{table.caption.52}}
\newlabel{tab:accuracy}{{2}{34}{Similar tools (top-2) for "hisat" extracted using full-rank documents-tokens matrices}{table.caption.52}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Similar tools (top-2) for "hisat" extracted using documents-tokens matrices reduced to 5\% of full-rank}}{34}{table.caption.53}}
\newlabel{tab:accuracy}{{3}{34}{Similar tools (top-2) for "hisat" extracted using documents-tokens matrices reduced to 5\% of full-rank}{table.caption.53}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Similarity matrices computed using full-rank document-tokens matrices}}{35}{figure.caption.33}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Distribution of weights learned for similarity matrices computed using full-rank documents-tokens matrices}}{36}{figure.caption.34}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Similarity matrices computed using document-tokens matrices reduced to 70\% of their full-rank}}{37}{figure.caption.35}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Distribution of weights learned for similarity matrices computed using documents-tokens matrices reduced to $70\%$ of their full-rank}}{38}{figure.caption.36}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Similarity matrices computed using document-tokens matrices reduced to $30\%$ of their full-rank}}{39}{figure.caption.37}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Distribution of weights learned for similarity matrices computed using documents-tokens matrices reduced to $30\%$ of their full-rank}}{40}{figure.caption.38}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Similarity matrices computed using document-tokens matrices reduced to $5\%$ of their full-rank}}{41}{figure.caption.39}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Distribution of weights learned for similarity matrices computed using documents-tokens matrices reduced to $5\%$ of their full-rank}}{42}{figure.caption.40}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Mean squared error using full-rank and multiple estimations of low-rank (latent semantic analysis approach}}{43}{figure.caption.42}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Average of uniformly and optimally weighted similarity scores computed using full-rank documents-tokens matrices across all tools}}{44}{figure.caption.43}}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Average of uniformly and optimally weighted similarity scores computed using documents-tokens matrices reduced to $5\%$ of full-rank across all tools}}{45}{figure.caption.44}}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces Documents-tokens matrices for paragraph vectors approach}}{46}{figure.caption.47}}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces Similarity matrices using paragraph vectors approach}}{47}{figure.caption.48}}
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces Distribution of weights for similarity matrices computed using documents-tokens matrices for paragraph vectors approach}}{48}{figure.caption.49}}
\@writefile{lof}{\contentsline {figure}{\numberline {31}{\ignorespaces Average of uniformly and optimally weighted similarity scores across all tools for paragraph vectors approach}}{49}{figure.caption.50}}
\@writefile{lof}{\contentsline {figure}{\numberline {32}{\ignorespaces Mean squared error across all tools over iterations for paragraph vectors approach}}{50}{figure.caption.51}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Similar tools (top-2) for "hisat" extracted using paragraph vectors approach}}{51}{table.caption.54}}
\newlabel{tab:accuracy}{{4}{51}{Similar tools (top-2) for "hisat" extracted using paragraph vectors approach}{table.caption.54}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Conclusion}{52}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Tools data}{52}{section.5.1}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Approaches}{52}{section.5.2}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Optimization}{53}{section.5.3}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Future work}{54}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Get true similarity values}{54}{section.6.1}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Correlation}{54}{section.6.2}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Other error functions}{54}{section.6.3}}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}More tools}{54}{section.6.4}}
\@writefile{toc}{\contentsline {part}{\numberline {II}Predict next tools in Galaxy workflows}{55}{part.2}}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Introduction}{56}{chapter.7}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chap:introduction}{{7}{56}{Introduction}{chapter.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Galaxy workflows}{56}{section.7.1}}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Motivation}{57}{chapter.8}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chap:motivation_wf}{{8}{57}{Motivation}{chapter.8}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Previous work}{58}{chapter.9}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chap:previous_work_wf}{{9}{58}{Previous work}{chapter.9}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {10}Our approach}{59}{chapter.10}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chap:approach_wf}{{10}{59}{Our approach}{chapter.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.1}Next tools}{59}{section.10.1}}
\@writefile{toc}{\contentsline {section}{\numberline {10.2}Compatible next tools}{59}{section.10.2}}
\@writefile{toc}{\contentsline {section}{\numberline {10.3}Variation of number of compatible tools}{59}{section.10.3}}
\@writefile{toc}{\contentsline {section}{\numberline {10.4}Topk predictions - absolute precision, top3, top5}{59}{section.10.4}}
\@writefile{toc}{\contentsline {section}{\numberline {10.5}Encoding the compatible types into the label vector}{59}{section.10.5}}
\@writefile{toc}{\contentsline {section}{\numberline {10.6}Compatible types just for verification}{59}{section.10.6}}
\@writefile{toc}{\contentsline {section}{\numberline {10.7}Length of input sequences}{59}{section.10.7}}
\@writefile{toc}{\contentsline {chapter}{\numberline {11}Experiments}{60}{chapter.11}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chap:experiments_wf}{{11}{60}{Experiments}{chapter.11}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {12}Results and analysis}{61}{chapter.12}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chap:results_analysis_wf}{{12}{61}{Results and analysis}{chapter.12}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {13}Conclusion}{62}{chapter.13}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chap:conclusion_wf}{{13}{62}{Conclusion}{chapter.13}{}}
\bibstyle{ieeetr}
\bibdata{bib/topic1}
\@writefile{toc}{\contentsline {chapter}{\numberline {14}Future work}{63}{chapter.14}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chap:future_work_wf}{{14}{63}{Future work}{chapter.14}{}}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{63}{chapter.14}}
\bibcite{Foltz1996}{1}
\bibcite{DBLP:journals/corr/LeM14}{2}
\bibcite{KaoudiQTCA17}{3}
\bibcite{LiptonKEW15}{4}
\bibcite{SakSB14}{5}
\bibcite{RobertsonBM25}{6}
\bibcite{Shapiro2000}{7}
\bibcite{Landauer1998}{8}
\bibcite{DBLP:journals/corr/Yang15b}{9}
\bibcite{Ivchenko1998}{10}
\bibcite{articleRuderS}{11}
\bibcite{Sutskever}{12}
\bibcite{Botev}{13}
\global\@altsecnumformattrue
