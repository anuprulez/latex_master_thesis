\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Foltz1996}
\citation{DBLP:journals/corr/LeM14}
\citation{KaoudiQTCA17}
\citation{LiptonKEW15}
\citation{SakSB14}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{2}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chap:introduction}{{1}{2}{Introduction}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Galaxy}{2}{section.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Basic flow of dataset transformation}}{2}{figure.caption.8}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Galaxy tools}{3}{section.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Common features of two tools using venn diagram}}{3}{figure.caption.9}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Motivation}{4}{section.1.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Similarity knowledge graph consisting of tools as nodes}}{4}{figure.caption.10}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Approach}{6}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chap:approach}{{2}{6}{Approach}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Extract tools data}{6}{section.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Select tools attributes}{6}{subsection.2.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Sequence of steps to find similar tools}}{7}{figure.caption.11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Clean tools data}{7}{subsection.2.1.2}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Remove duplicates and stopwords}{7}{section*.12}}
\citation{Robertson:2009:PRF:1704809.1704810}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Use stemming}{8}{section*.13}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Learn relevance for words}{8}{section*.16}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Distribution of tokens for all the attributes of tools}}{9}{figure.caption.14}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Tool, document and tokens}}{10}{figure.caption.15}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces A sparse documents-tokens matrix}}{11}{table.caption.17}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:accuracy}{{1}{11}{A sparse documents-tokens matrix}{table.caption.17}{}}
\citation{Foltz1996}
\citation{Shapiro2000}
\citation{Landauer1998}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Heatmap for documents-tokens matrices}}{12}{figure.caption.18}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Learn dense vector for a document}{13}{section.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Latent semantic indexing}{13}{subsection.2.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Pictorial representation of singular value decomposition}}{13}{figure.caption.19}}
\citation{DBLP:journals/corr/Yang15b}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Low-rank approximation}{14}{section*.20}}
\citation{DBLP:journals/corr/LeM14}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Singular values of documents-tokens matrices}}{15}{figure.caption.21}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Paragraph vectors}{15}{subsection.2.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Singular values of documents-tokens matrices with their respective ranks}}{16}{figure.caption.22}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces The variation of fraction of ranks of documents-tokens matrices with the fraction of sum of singular values}}{17}{figure.caption.23}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Approach}{17}{section*.25}}
\citation{DBLP:journals/corr/LeM14}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Low-rank representations of documents-tokens matrices}}{18}{figure.caption.24}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Distributed memory approach for paragraph vectors}}{19}{figure.caption.26}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Similarity measures}{19}{section.2.3}}
\newlabel{pv}{{9}{19}{}{Hfootnote.16}{}}
\citation{Ivchenko1998}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Distributed bag-of-words approach for paragraph vectors}}{20}{figure.caption.27}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Cosine similarity}{20}{subsection.2.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Jaccard index}{20}{subsection.2.3.2}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Optimization}{21}{section.2.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Gradient descent}{22}{subsection.2.4.1}}
\citation{articleRuderS}
\citation{articleRuderS}
\citation{Sutskever}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Learning rate decay}{23}{subsection.2.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Decay of learning rate for gradient descent optimizer}}{24}{figure.caption.28}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Weight update}{24}{subsection.2.4.3}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Momentum}{24}{section*.29}}
\citation{Botev}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Nesterov\IeC {\textquoteright }s accelerated gradient}{25}{section*.30}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Gradient verification}{25}{section*.31}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Verification of gradient for the error function}}{26}{figure.caption.32}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Experiments}{27}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Amount of help text}{27}{section.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}One and two sources instead of three}{27}{section.3.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Similarity measures}{27}{section.3.3}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Latent Semantic Analysis}{27}{section.3.4}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Paragraph Vector}{28}{section.3.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Distributed bag-of-words}{28}{subsection.3.5.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Gradient Descent}{28}{section.3.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.1}Learning rates}{29}{subsection.3.6.1}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Results and Analysis}{30}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Latent Semantic Analysis}{30}{section.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Full-rank matrices}{30}{subsection.4.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}70\% of full-rank}{30}{subsection.4.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Similarity matrices computed using full-rank document-tokens matrices}}{31}{figure.caption.33}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}30\% of full-rank}{31}{subsection.4.1.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Distribution of weights learned for similarity matrices computed using full-rank documents-tokens matrices}}{32}{figure.caption.34}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.4}5\% of full-rank}{32}{subsection.4.1.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Similarity matrices computed using document-tokens matrices reduced to 70\% of their full-rank}}{33}{figure.caption.35}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.5}Improvement verification}{33}{subsection.4.1.5}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Reduction in error}{33}{section*.41}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Distribution of weights learned for similarity matrices computed using documents-tokens matrices reduced to $70\%$ of their full-rank}}{34}{figure.caption.36}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Paragraph vectors}{34}{section.4.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Comparison of latent semantic analysis and paragraph vectors approach}{34}{section.4.3}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Similar tools (top-2) for "hisat" extracted using full-rank documents-tokens matrices}}{35}{table.caption.49}}
\newlabel{tab:accuracy}{{2}{35}{Similar tools (top-2) for "hisat" extracted using full-rank documents-tokens matrices}{table.caption.49}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Similar tools (top-2) for "hisat" extracted using documents-tokens matrices reduced to 5\% of full-rank}}{35}{table.caption.50}}
\newlabel{tab:accuracy}{{3}{35}{Similar tools (top-2) for "hisat" extracted using documents-tokens matrices reduced to 5\% of full-rank}{table.caption.50}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Similar tools (top-2) for "hisat" extracted using paragraph vectors approach}}{35}{table.caption.51}}
\newlabel{tab:accuracy}{{4}{35}{Similar tools (top-2) for "hisat" extracted using paragraph vectors approach}{table.caption.51}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Similarity matrices computed using document-tokens matrices reduced to $30\%$ of their full-rank}}{36}{figure.caption.37}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Distribution of weights learned for similarity matrices computed using documents-tokens matrices reduced to $30\%$ of their full-rank}}{37}{figure.caption.38}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Similarity matrices computed using document-tokens matrices reduced to $5\%$ of their full-rank}}{38}{figure.caption.39}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Distribution of weights learned for similarity matrices computed using documents-tokens matrices reduced to $5\%$ of their full-rank}}{39}{figure.caption.40}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Mean squared error using full-rank and multiple estimations of low-rank (latent semantic analysis approach}}{40}{figure.caption.42}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Average of uniformly and optimally weighted similarity scores computed using full-rank documents-tokens matrices across all tools}}{41}{figure.caption.43}}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Average of uniformly and optimally weighted similarity scores computed using documents-tokens matrices reduced to $5\%$ of full-rank across all tools}}{42}{figure.caption.44}}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces Documents-tokens matrices for paragraph vectors approach}}{43}{figure.caption.45}}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces Similarity matrices using paragraph vectors approach}}{44}{figure.caption.46}}
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces Distribution of weights for similarity matrices computed using documents-tokens matrices for paragraph vectors approach}}{45}{figure.caption.47}}
\@writefile{lof}{\contentsline {figure}{\numberline {31}{\ignorespaces Average of uniformly and optimally weighted similarity scores across all tools for paragraph vectors approach}}{46}{figure.caption.48}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Conclusion}{47}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Tools data}{47}{section.5.1}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Approaches}{47}{section.5.2}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Optimization}{48}{section.5.3}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Future Work}{49}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Get true value}{49}{section.6.1}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Correlation}{49}{section.6.2}}
\bibstyle{ieeetr}
\bibdata{bib/topic1}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{50}{section.6.2}}
\bibcite{Foltz1996}{1}
\bibcite{DBLP:journals/corr/LeM14}{2}
\bibcite{KaoudiQTCA17}{3}
\bibcite{LiptonKEW15}{4}
\bibcite{SakSB14}{5}
\bibcite{Robertson:2009:PRF:1704809.1704810}{6}
\bibcite{Shapiro2000}{7}
\bibcite{Landauer1998}{8}
\bibcite{DBLP:journals/corr/Yang15b}{9}
\bibcite{Ivchenko1998}{10}
\bibcite{articleRuderS}{11}
\bibcite{Sutskever}{12}
\bibcite{Botev}{13}
